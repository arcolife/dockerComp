{"name":"DockerComp","tagline":"Dockerized Distributed Computing","body":"dockerComp\r\n==========\r\n\r\n### Highlights \r\n\r\n- Twice the local edition winner (BLR, IN) for [docker global hackathon](https://www.docker.com/community/globalhackday)\r\n- 2nd prize in [Dora Hackathon](http://ideahub.thu.io/#/DoraHacks[0])\r\n\r\n**GOAL**\r\n\r\nTo setup a basic prototype for distributed computing in docker. If time permits, add a complex \r\ncomputing task.\r\n\r\n**INTRODUCTION**\r\n\r\nFor the purpose of Distributed (Scientific) Computing, scientists across the world have been \r\nmostly using pre-configured VM images to let the client volunteer in contributing \r\ntowards micro-processing tasks  that involve processing of raw data received in \r\nchunks over the network. \r\n\r\nBut, since the introduction of Docker, life has changed and so have the performance \r\nbenchmarks. We propose an system that uses the benefits of Docker to hopefully perform \r\nfar better than the currently achieved milestones through VMs. The VMs have a huge \r\noverhead of starting up, as compared to Docker containers. Moreover, we don't even need \r\nto explain the difference between running more than one VM on a HostOS compared to \r\nrunning multiple docker containers on that same machine! See the point? :)\r\n\r\n- Youtube Video Explaining this project:\r\n  \r\n  [![Here's a video for DockerComp](http://img.youtube.com/vi/lIp2nrOnKFs/0.jpg)](http://www.youtube.com/watch?v=lIp2nrOnKFs)\r\n\r\n  [![Here's a current screenshot of installation and first run](https://arcolife.files.wordpress.com/2015/09/installation-and-first-contact.png)](https://arcolife.wordpress.com/2015/09/21/docker-global-hack-day-mania-dockercomp/)\r\n  \r\n  [![Here's a current screenshot of client logs when server goes down: constant polling](https://arcolife.files.wordpress.com/2015/09/communicatio-and-outage.png)](https://arcolife.wordpress.com/2015/09/21/docker-global-hack-day-mania-dockercomp/)\r\n  \r\n- [Click here](http://asciinema.org/a/13557) for Screencast for running just one script on client side. \r\n\r\n**INSTALLATION**\r\n\r\n- Server side (src/server/):\r\n\r\n  - Make sure that your 'src/server/' is up and running, either locally (for test purpose), \r\n     or if its deployed elsewhere, then the hostname/IP and Port is provided in the environment \r\n     variables as under `$DC_HOST` and `$DC_PORT`.\r\n\r\n     (refer next major point on 'Client side' for this script)\r\n\r\n  - Do ensure that for running the server, you need to install mongoDB. Refer to following: \r\n    [install_mongo guide](https://github.com/arcolife/dockerComp/blob/master/src/server/install_mongo)\r\n    and then set the env variables `U_DB, U_USER and U_PASS` giving the same values to them as the\r\n    db name, it's user and password set while setting up mongoDB.\r\n\r\n\r\n  - Ensure that you've installed deps from `dockerComp/src/server/requirements.txt`\r\n\r\n  - To run the src/server, open up a terminal, go to dockerComp/src/server/ and run ```$ ./start```\r\n    This starts the server locally on your machine.\r\n\r\n\r\n- Client side (src/client/):\r\n\r\n  - Note: For server side deployement (i.e., the server that basically is responsible for distributing data \r\n      to clients), It has to be deployed somewhere and it's IP has to be provided in your `configuration` file. \r\n      And then you may distribute the script `installer.sh` alongwith the `configuration` to the clients. \r\n\r\n\r\n  - Download [This Script](https://github.com/arcolife/dockerComp/raw/master/installer.sh) and run \r\n\r\n  ```$ ./installer.sh``` [configure your Server location for this script, as under `$DC_HOST` & `$DC_PORT` ]\r\n\r\n  - Once installed, the daemon output would lie in `$HOME/dockerComp/src/client/scripts/nohup.out` and\r\n    the daemon itself, would like in  `$HOME/dockerComp/src/client/scripts/slave_manager`. To kill the\r\n    daemon, you need to run `$ kill -9 $(ps -e | grep slave_manager | awk -F' ' '{print $1}')`\r\n\r\nShould you need to remove all traces of dockerComp from your machine, just run the script 'cleanup`\r\nincluded in the source code of this project root.\r\n\r\nCheers! :)\r\n\r\n**NOTES**\r\n\r\n- Demo link to be updated soon. \r\n\r\n- In case you're curious how to go about running this from client side:\r\n \r\n  - So once the server is up and running, all one has to do is download and run installer.sh\r\n\r\n- Docker Image: ``` $ docker pull arcolife/docker_comp ``` (will be kept updated)\r\n\r\n\r\n**FAQ**\r\n\r\nRefer to Wiki .. [click Here!](https://github.com/arcolife/dockerComp/wiki).\r\n\r\nReferences: \r\n\r\n     - http://www.rightscale.com/blog/sites/default/files/docker-containers-vms.png \r\n     - http://en.wikipedia.org/wiki/Docker_%28software%29#cite_ref-3\r\n\r\nSo, just to give you a context of this whole project, take a look at this project called\r\n[CernVM](http://cernvm.cern.ch/portal/). This is a really awesome project, developed to\r\nhelp collect CERN's LHC data and perform data analysis on a volunteer's computer or even on\r\ncommercial clouds. Just imagine if the whole process of using VM was dockerized!    \r\n \r\n\r\n**FEATURES**\r\n\r\n- Can be used for:\r\n      - Image Processing\r\n      - General Data Analysis\r\n      - Scientific Computing\r\n      - CrowdSourcing projects.\r\n\r\n\r\n**FUTURE GOALS** \r\n\r\n- Make this a pluggable dockerized distributed computing tool, where you just have to include \r\n  a compution task (say, map-reduce) and make it send data to clients. The app should be able \r\n  to handle the rest.\r\n\r\n- Benchmark results and compare with existing methodologies. \r\n\r\n**TESTS**\r\n\r\n- From client side:\r\n  - although the default connection establishment test is included with install scripts;\r\n    run ```$ src/client/scripts/test_server_conn``` (make sure env vars `DC_HOST` and `DC_PORT` are set)\r\n\r\n- From server side:\r\n  - TBD\r\n\r\n- Workloads:\r\n  - Currently a simple task. TBD.\r\n\r\n\r\n**WORKFLOW**\r\n\r\n1. Server\r\n\r\n   - Dashboard to Manage:\r\n     - No. of Clients (and # of containers per client)\r\n     - Resources allocated to the containers\r\n   \r\n   - Master app  that manages data sent to each client and checks for integrity.\r\n\r\n2. Client\r\n\r\n   - Installation of Docker\r\n   - Starting Containers\r\n   - Installation of Application inside the Container\r\n   - Connection Establishment with the Server.\r\n   - Scripts for the computation\r\n   - Error Reporting\r\n\r\n\r\n**REFERENCES**\r\n\r\n1. https://github.com/cernvm\r\n2. http://en.wikipedia.org/wiki/List_of_distributed_computing_projects\r\n3. http://www.rightscale.com/blog/sites/default/files/docker-containers-vms.png \r\n4. http://www.psc.edu/science/\r\n5. http://pybossa.com/\r\n6. https://okfn.org/press/releases/crowdcrafting-putting-citizens-control-citizen-science/\r\n7. http://www.mediaagility.com/2014/docker-the-next-big-thing-on-cloud/\r\n8. http://cernvm.cern.ch/portal/\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}